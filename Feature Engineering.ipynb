{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled5.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DyCx_--8ZSnk",
        "outputId": "00283f02-ff1b-4af4-db3a-e0cfccc8ac47"
      },
      "source": [
        "# Importing the necessary modules.\n",
        "\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "tf.__version__\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.preprocessing.text import one_hot\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.layers import Dense\n",
        "import nltk\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Importing the labeled dataset.\n",
        "Labelled_data=pd.read_csv('data_to_label.csv')\n",
        "\n",
        "Labelled_data.head()\n",
        "Labelled_data=Labelled_data.dropna()\n",
        "\n",
        "# Get the Independent Features\n",
        "X=Labelled_data.drop('Skill',axis=1)\n",
        "\n",
        "# Get the Dependent features\n",
        "y=Labelled_data['Skill']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7v8-ben3Zfl1"
      },
      "source": [
        "# Setting the Vocabulary size\n",
        "voc_size=100000\n",
        "PotentialWords=X.copy()\n",
        "PotentialWords.reset_index(inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Gbr1Hp0Zjd2",
        "outputId": "f62927ea-3b16-4e88-e572-8ecedcefde5b"
      },
      "source": [
        "# Building the corpus after removing stop words in each sentence in the job description.\n",
        "\n",
        "ps = PorterStemmer()\n",
        "corpus = []\n",
        "for i in range(len(PotentialWords)):\n",
        "    PotentialWord = re.sub('[^a-zA-Z]', ' ', PotentialWords['Word'][i])\n",
        "    PotentialWord = PotentialWord.lower()\n",
        "    PotentialWord = PotentialWord.split()\n",
        "    \n",
        "    PotentialWord = [ps.stem(word) for word in PotentialWord if not word in stopwords.words('english')]\n",
        "    PotentialWord = ' '.join(PotentialWord)\n",
        "    corpus.append(PotentialWord)\n",
        "\n",
        "print(len(corpus))\n",
        "print(corpus)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1674\n",
            "['look', 'selenium', 'engin', '', 'must', 'solid', 'java', 'code', 'skill', 'sever', 'open', 'month', 'hire', '', 'must', 'abl', 'go', 'perm', 'someon', '', 'year', 'experi', '', 'import', 'qualiti', 'eager', 'aptitud', '', 'posit', 'purpos', '', 'want', 'forefront', 'cut', 'edg', 'technolog', '', 'introduc', 'solut', 'problem', '', 'exist', '', 'abil', 'see', 'result', 'success', '', 'client', 'assur', 'growth', 'collabor', 'develop', 'team', 'creat', 'tool', 'aid', 'engin', 'build', '', 'test', '', 'debug', '', 'releas', 'softwar', '', 'touch', 'million', 'user', 'increas', 'rate', 'develop', 'ensur', 'product', 'method', 'test', '', 'expert', 'softwar', 'health', '', 'testabl', '', 'sustain', '', 'softwar', 'engin', 'test', 'client', '', 'expect', 'build', 'flexibl', 'scalabl', 'solut', 'work', 'complex', 'challeng', 'larg scale', 'comput', 'util', 'skill', 'data', 'structur', 'object', 'orient', 'program', '', 'major', 'task', '', 'respons', 'key', 'account', '', 'lead', 'contribut', 'engin', 'effort', 'plan', 'execut', 'deliveri', 'solv', 'complex', 'engin', 'problem', 'tool', 'test', '', '', 'design', 'build', 'advanc', 'autom', 'test', 'framework', '', '', 'build', 'tool', 'help', 'develop', 'measur', 'increas', 'veloc', '', '', 'adopt', 'best', 'practic', 'softwar', 'health', '', 'test', '', 'sustain', '', '', 'analyz', 'break', 'complex', 'softwar', 'system', 'collabor', 'develop', 'team', 'improv', 'overal', 'design', '', 'natur', 'scope', '', '', 'typic', 'report', 'manag', 'test', 'engin', '', 'associ', 'report', 'person', 'role', 'perman', 'basi', '', 'analyz', 'resolv', 'complex', 'qualiti', 'issu', 'critic', 'solut', 'deliveri', '', 'fast pace', 'environ', 'freedom', 'respons', 'prefer', 'qualif', '', 'hand', 'java', 'develop', 'experi', '', 'profici', 'ab', 'initio', 'etl', 'batch', 'test', '', 'hand', 'knowledg', 'soap', 'ui', '', 'itko', 'lisa', '', 'selenium', '', 'hand', 'experi', 'unix', '', 'ksh', '', 'bourn', 'shell', 'script', '', 'strong', 'script', 'knowledg', 'java', '', 'groovi', 'jmeter', '', 'strong', 'develop', 'experi', 'work', 'web', 'servic', '', 'rest', 'soap', '', '', 'experi', 'build', 'test', 'autom', 'framework', 'web', 'servic', 'use', 'soap', 'ui', '', 'groovi', '', 'lisa', '', 'profici', 'sql', '', 'work', 'knowledg', 'svn', 'jenkin', '', 'build', 'develop', 'process', '', 'ecommerc retail', 'qa', 'experi', '', 'excel', 'written', 'verbal', 'commun', 'skill', '', 'self motiv', 'strong', 'work', 'ethic', 'posit', 'attitud', '', 'desir', 'work', 'fast pace', '', 'result', 'orient', 'team', '', 'experi', 'script', 'languag', 'perl', '', 'passion', 'understand', '', 'learn', '', 'dissect', 'improv', 'new', 'technolog', '', 'profici', 'one', 'follow', '', 'retail', 'applic', '', 'window', 'platform', '', 'unix', 'platform', '', 'java', '', 'relat', 'databas', '', 'webspher', 'applic', 'server', '', 'webspher', 'commerc', '', 'webspher', 'mq', '', 'comprehens', 'understand', 'system', '', 'applic', 'network', 'knowledg', '', 'skill', '', 'abil', 'compet', '', '', 'profici', 'one', 'follow', '', 'retail', 'applic', '', 'window', 'platform', '', 'unix', 'platform', '', 'mv', 'cobol', '', 'java', '', 'j', 'ee', '', 'relat', 'databas', '', 'webspher', 'applic', 'server', '', 'webspher', 'commerc', '', 'webspher', 'mq', '', 'network', '', 'voic', '', 'lan', '', 'wan', '', '', 'sap', '', 'siebel', '', 'peoplesoft', '', 'comprehens', 'understand', 'system', '', 'applic', 'network', '', 'strong', 'problem', 'solv', 'analyt', 'skill', '', 'strong', 'oral', 'written', 'commun', 'skill', '', 'abil', 'coordin', 'collabor', 'across', 'cross function', 'team', 'univers', 'chicago', 'rapidli', 'grow', 'secur', 'program', 'mani', 'opportun', 'motiv', 'person', 'work', 'varieti', 'role', 'mani', 'technic', 'area', '', 'posit', 'respons', 'provid', 'incid', 'respons', '', 'inform', 'secur', 'assess', '', 'monitor', '', 'system', 'administr', 'gener', 'direct', 'inform', 'secur', 'offic', 'lead', 'inform', 'secur', 'engin', '', 'essenti', 'function', '', 'execut', 'secur', 'network', 'monitor', 'incid', 'respons', 'procedur', '', 'lead', 'particip', 'secur', 'project', '', 'administ', 'secur', 'system', '', 'includ', 'updat', '', 'backup', '', 'upgrad', 'consult', '', 'advis', '', 'provid', 'secur', 'assess', 'servic', 'applic', 'develop', 'acquisit', 'project', 'assess', 'secur', 'requir', 'control', 'ensur', 'secur', 'control', 'implement', 'plan', '', 'research', 'secur', 'issu', 'contribut', 'secur', 'commun', '', 'web', 'page', '', 'blog', '', 'awar', 'materi', '', 'document', 'intern', 'process', '', 'write', 'secur', 'standard', 'guidelin', '', 'duti', 'assign', 'qualif', '', 'bachelor', '', 'degre', 'minimum', 'four', 'year', 'experi', 'inform', 'technolog', 'field', 'equival', 'combin', 'educ', 'experi', 'requir', '', 'minimum', 'two', 'year', 'profession', 'experi', 'technic', 'inform', 'secur', 'role', 'requir', '', 'experi', 'administ', 'linux unix', 'system', 'requir', '', 'experi', 'administ', 'window', 'system', 'prefer', '', 'experi', 'program', 'script', 'languag', 'perl', 'python', 'strongli', 'prefer', '', 'univers', 'chicago', 'affirm', 'action equal', 'opportun disabl veteran', 'employ', 'discrimin', 'basi', 'race', '', 'color', '', 'religion', '', 'sex', '', 'sexual', 'orient', '', 'gender', 'ident', '', 'nation', 'ethnic', 'origin', '', 'age', '', 'statu', 'individu', 'disabl', '', 'protect', 'veteran', 'statu', '', 'genet', 'inform', '', 'protect', 'class', 'law', '', 'addit', 'inform', 'pleas', 'see', 'univers', '', 'notic', 'nondiscrimin staff', 'job', 'seeker', 'need', 'reason', 'accommod', 'complet', 'applic', 'process', 'call', '', '', 'email', 'talentacquisit', '', 'uchicago edu', 'request', '', 'galax solutionseveri', 'day', '', 'solut', 'affect', 'peopl', 'throughout', 'world', '', 'fortun', 'compani', 'start up', '', 'galax', 'develop', 'implement', 'strateg', 'project', 'critic', 'success', 'custom', '', 'busi', 'live', 'ten', 'million', 'peopl', '', 'twenti five', 'year', '', 'grown', 'evolv', 'multi nation', 'firm', 'employ', 'team', 'member', 'worldwid', '', '', 'done', 'evolv', '', 'took', 'collabor', 'innov', 'get', '', 'take', 'collabor', 'innov', 'get', '', 'custom', '', 'want', 'tomorrow', '', 'mean', 'employe', '', 'secur', 'establish', 'compani', '', 'benefit', 'work', 'compani', 'great', 'mind', '', 'hard', 'work', '', 'leadership', 'innov', 'highli', 'regard', 'reward', '', 'thoma', 'edison', 'said', '', '', '', 'way', 'better', '', 'find', '', '', 'want', 'employe', 'find', '', '', 'look', 'creativ', 'peopl', '', 'entrepreneuri', 'spirit', '', 'look', 'work', 'awesom', 'project', '', 'sound', 'like', '', 'come', 'work', 'us', '', 'find', 'mean', 'part', 'galax', 'team', '', '', 'alway', 'easi', '', 'import', 'work', 'never', '', '', 'wearegalax', 'develop', 'practic', 'roadmap', 'enterpris wide', 'bi', 'report', 'analyt', 'platform', 'consider', 'busi', 'object', '', 'technolog', 'consider', 'budget', '', 'defin', 'overal', 'bi', 'data', 'architectur', 'could', 'includ', '', 'etl', 'process', '', 'od', '', 'edw', '', 'data', 'mart', 'data', 'lake provid', 'bi', 'technic', 'architectur', 'guidanc', 'project', 'project', 'team', 'ensur', 'new', 'initi', 'enabl', 'effect', 'data', 'report develop', 'new', 'report', 'solut', 'requiredidentifi', '', 'evalu', '', 'provid', 'propos', 'solut', 'identifi', 'process', 'data', 'qualiti', 'issuesdocu', 'best', 'practic', 'methodolog', 'develop', 'standard', '', 'data', 'govern', '', 'version', 'control', '', 'deploy', 'chang', 'manag perform', 'qualiti', 'assur', 'test', 'report', 'dashboard', '', 'perform', 'user', 'accept', 'test', '', 'uat', '', '', 'technic', 'experi', '', 'core', 'understand', 'busi', 'intellig', '', 'data', 'wareh', 'technolog', '', 'methodolog', '', 'techniqu', '', 'data', 'discoveri', '', 'data', 'sourc', '', 'present', 'layer', '', 'etc', '', 'proven', 'experi', 'deliv', 'success', 'solutionsexcel', 'knowledg', 'data', 'warehous', 'principl', 'report experi', 'design', 'build', 'enterpris', 'data', 'warehous extens', 'experi', 'bi', 'report', '', 'web', 'mobil', 'dashboard', 'develop', '', 'experi', 'multipl', 'databas', 'platformsexperi', 'data', 'analysi', '', 'assess', 'data', 'qualiti', 'develop', 'correct', 'actionsthorough', 'understand', 'complex', 'larg', 'scale', 'data', 'modelsunderstand', 'common', 'sdlc', 'practic methodologiesexperi', 'work', 'end', 'user', 'gather', 'requirementsexperi', 'use', 'data', 'discoveri', 'toolsunderstand', 'rdbm', 'java', 'developerful time direct hirebolingbrook', '', 'il', 'client', 'lead', 'edg', 'softwar', 'develop', 'organ', 'uniqu', 'interest', 'industri', '', 'provid', 'train', 'help', 'board', '', 'excel', 'cultur', 'energet', '', 'challeng', '', 'team', 'orient', '', 'casual', '', 'jean', 'ok', '', '', 'work life', 'balanc', '', 'outstand', 'benefit', 'packag', '', 'encourag', 'commun', 'atmospher', 'creativ', 'bright', 'mind', 'reward', '', 'look', 'java', 'develop', 'join', 'compani', '', 'posit', 'give', 'someon', 'abil', 'input', 'system', 'design', 'grow', 'compani', '', 'person', 'work', 'team', 'focus', 'develop', 'mainten', 'variou', 'applic', 'support', 'client', '', 'posit', 'build', 'applic', 'scratch', 'involv', 'implement', 'process', '', 'abil', 'commun', 'work', 'directli', 'client', 'essenti', '', 'success', 'candid', 'self direct', 'problem', 'solver', 'experi', 'applic', 'design', '', 'java jdbc', 'develop', '', 'multi thread', '', 'interest', '', 'pleas', 'email', 'resum', 'contact', 'kgalecki', '', 'transtechit com', 'overview', '', 'primari', 'applic', 'person', 'initi', 'work', 'serv', 'middl', 'tier', '', 'back', 'relat', 'databas', '', 'oracl', '', 'sql', 'server', '', 'mysql', '', 'via', 'jdbc', '', 'front', 'compani', '', 'transact base', 'law', 'enforc', 'messag', 'switch', 'via', 'proprietari', 'tcp ip', 'protocol', '', 'primari', 'respons', '', '', 'develop', 'robust', '', 'high', 'perform', '', 'flexibl', 'applic', 'analyz', 'diagnos', 'applic', 'error', 'write', 'applic', 'document', 'clearli', 'commun', 'statu', 'manag', 'requir', 'skill', '', '', 'core', 'java', 'experi', 'creat', 'jdbc', 'interfac', 'relat', 'databas', 'multithread', '', 'basic', 'experi', '', '', 'abl', 'develop', 'work', 'linux', '', 'aix', '', 'unix', 'deriv', 'os', '', 'sql', 'socket', 'level', 'messag', '', 'basic', 'experi', '', '', 'understand', 'data', 'structur', 'self direct', 'problem', 'solv', 'abl', 'clearli', 'commun', 'verbal', 'write', 'bachelor', 'degre', 'comput', 'scienc', 'prefer', 'skill', '', '', 'c', '', 'c', '', 'knowledg', 'one', 'script', 'languag', 'experi', 'type', 'version', 'control', 'tool', '', 'prefer', 'dvc', 'socket', 'level', 'messag', 'non technic', 'requir', '', '', 'must', 'abl', 'pass', 'state', 'feder', 'background', 'check', 'state', 'union', 'willing', 'travel', 'throughout', 'unit', 'state', 'requir', '', 'less', '', '', '', 'minimum', 'year', 'relev', 'experi', 'midtown', 'base', 'high', 'tech', 'firm', 'immedi', 'need', 'innov', 'devop', 'engin', 'help', 'defin', 'dev', '', 'op', 'relat', 'process', '', 'build', 'autom', '', 'posit', '', 'dev', '', 'op', 'engin', 'need', 'engin', 'technic', 'solut', 'well', 'perform', 'process', 'engin', '', 'ideal', 'candid', 'strong', 'script', 'skill', 'autom', 'well', 'experi', 'configur', 'manag', '', 'server', 'deploy', '', 'continu', 'integr', 'experi', 'tool', 'chef', '', 'puppet', '', 'etc', '', 'must', 'experi', 'virtual', 'use', 'vmware', 'linux', 'experi', 'prefer', '', 'experi', 'go', '', 'docker', '', 'ansibl', '', 'microservic', '', 'cloud', 'highli', 'desir', '', 'perman', 'posit', 'innov', 'technolog', 'firm', 'midtown', 'offer', 'excel', 'benefit', 'includ', 'bleed', 'edg', 'technolog', '', 'gener', 'pto', '', 'match', '', 'k', '', '', 'high tech', 'offic', 'environ', '', 'casual', 'dress', 'collabor', 'cultur', '', 'need', 'immedi', '', '', 'categori', '', 'develop', '', 'architect', 'name', 'look', 'senior', 'sap', 'fico', 'architect', 'join', 'us', 'fulltim', 'support', 'ongo', 'project', 'custom', '', 'must', 'excel', 'pre sale', 'experi consult', 'readi', '', 'travel', '', 'interest', '', 'pleas', 'send', 'us', 'updat', 'resum', '', 'best', 'time', 'contact', 'number', 'girish', '', 'dot', '', 'bandaru', '', '', 'yash', '', 'dot', '', 'com', 'discuss', 'opportun', '', 'thank', '', 'regard', 'girish', 'bandaruyash', 'technolog', '', '', 'girish bandaru', '', 'yash com', 'network', 'engin', 'job', 'descript', 'network', 'engin', 'respons', 'analyz', '', 'design', '', 'instal', '', 'configur', '', 'maintain', 'repair', 'network', 'infrastructur', 'applic', 'compon', '', 'network', 'engin', 'perform', 'wide', 'varieti', 'evalu', '', 'mainten', '', 'instal', 'train', 'task', 'ensur', 'comput', 'network', 'perform', 'meet', 'compani', 'user', 'satisfact', '', 'network', 'engin', 'also', 'provid', 'direct', '', 'inform', '', 'recommend', 'regard', 'network', 'configur', 'instal', '', 'primari', 'duti', 'respons', '', '', 'maintain', 'thorough', 'understand', 'basic', 'behind', 'internet', 'work', '', 'dn', 'secur', '', 'ip', 'rout', '', 'http', '', 'vpn', '', 'email', 'rout', '', 'spam', '', 'etc', '', '', '', 'configur', 'setup', 'cisco', 'firewal', '', 'vpn', 'concentr', 'secur', 'applianc', 'access', 'vital', 'busi', 'applic', '', 'design', '', 'setup', 'configur', 'complex', 'switch', 'environ', '', 'design', '', 'setup', 'configur', 'complex', 'wireless', 'network', 'support', 'open', 'secur', 'access', 'abil', 'support', 'voic', 'video', 'applic', '', 'maintain', 'thorough', 'understand', 'local', 'area', 'network', '', 'assist', 'design', 'multi server', 'environ', 'includ', 'ip', 'address', 'scheme', '', 'dn', '', 'win', '', 'etherchannel', '', 'bond', '', '', 'etc', '', '', 'configur', 'instal', 'client', 'server', 'network', 'softwar', 'upgrad', 'maintain', 'network', 'telecommun', 'system', '', '', 'maintain', 'multi site', 'network', 'oper', 'softwar', 'applic', '', 'oper', 'system', 'regular', 'mainten', 'privat', 'public', 'facil', '', 'manag', 'assign', 'project', 'program', 'compon', 'deliv', 'servic', 'accord', 'establish', 'object', '', '', 'respond', 'inquiri', 'staff', '', 'administr', '', 'servic', 'provid', '', 'site', 'personnel', 'outsid', 'vendor', 'etc', '', 'provid', 'technic', 'assist', 'support', '', 'supervis', 'administr', 'system', 'server', 'relat', 'network', 'ensur', 'avail', 'servic', 'author', 'user', '', 'date', 'post', '', '', '']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DUxUpDGEZm7y",
        "outputId": "c724d853-2277-427d-bc30-41b86dea2737"
      },
      "source": [
        "# Generating one-hot representations for each word in the corpus.\n",
        "\n",
        "onehot_repr=[one_hot(words,voc_size)for words in corpus] \n",
        "print(len(onehot_repr))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1674\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RDCQhlbUZqa_",
        "outputId": "280dde9d-4b37-4d81-8dbf-14c5f80fac8c"
      },
      "source": [
        "# Creating embedding docs with a vector of 5 dimensions to be passed to the LSTM. \n",
        "\n",
        "words_length=5\n",
        "embedded_docs=pad_sequences(onehot_repr,padding='pre',maxlen=words_length)\n",
        "print(len(embedded_docs))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1674\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YWYbxFNhZtWr",
        "outputId": "6fd69686-94c0-4105-ead8-171f1d707184"
      },
      "source": [
        "# Creating model\n",
        "embedding_vector_features=10\n",
        "model=Sequential()\n",
        "model.add(Embedding(voc_size,embedding_vector_features,input_length=words_length))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(1,activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "\n",
        "print(model.summary())\n",
        "print(len(embedded_docs),y.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_3 (Embedding)      (None, 5, 10)             1000000   \n",
            "_________________________________________________________________\n",
            "lstm_3 (LSTM)                (None, 100)               44400     \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 101       \n",
            "=================================================================\n",
            "Total params: 1,044,501\n",
            "Trainable params: 1,044,501\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "1674 (1674,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xTAGQkSRZw0w",
        "outputId": "17001a79-f7fc-4836-d2d0-20e7712acf2b"
      },
      "source": [
        "# Creating training and testing data.\n",
        "\n",
        "X_total=np.array(embedded_docs)\n",
        "y_total=np.array(y)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_total, y_total, test_size=0.20, random_state=40)\n",
        "\n",
        "# Training the model\n",
        "model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=50,batch_size=64)\n",
        "\n",
        "# Making predictions.\n",
        "y_pred=model.predict_classes(X_test)\n",
        "\n",
        "confusion_matrix(y_test,y_pred)\n",
        "accuracy_score(y_test,y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "21/21 [==============================] - 3s 48ms/step - loss: 0.6614 - accuracy: 0.8381 - val_loss: 0.5207 - val_accuracy: 0.8179\n",
            "Epoch 2/50\n",
            "21/21 [==============================] - 0s 22ms/step - loss: 0.4625 - accuracy: 0.8369 - val_loss: 0.4718 - val_accuracy: 0.8179\n",
            "Epoch 3/50\n",
            "21/21 [==============================] - 0s 22ms/step - loss: 0.4113 - accuracy: 0.8566 - val_loss: 0.4682 - val_accuracy: 0.8179\n",
            "Epoch 4/50\n",
            "21/21 [==============================] - 0s 23ms/step - loss: 0.4243 - accuracy: 0.8439 - val_loss: 0.4654 - val_accuracy: 0.8179\n",
            "Epoch 5/50\n",
            "21/21 [==============================] - 0s 22ms/step - loss: 0.4207 - accuracy: 0.8405 - val_loss: 0.4602 - val_accuracy: 0.8179\n",
            "Epoch 6/50\n",
            "21/21 [==============================] - 0s 23ms/step - loss: 0.4338 - accuracy: 0.8273 - val_loss: 0.4524 - val_accuracy: 0.8179\n",
            "Epoch 7/50\n",
            "21/21 [==============================] - 0s 22ms/step - loss: 0.3800 - accuracy: 0.8486 - val_loss: 0.4326 - val_accuracy: 0.8179\n",
            "Epoch 8/50\n",
            "21/21 [==============================] - 0s 23ms/step - loss: 0.3756 - accuracy: 0.8392 - val_loss: 0.4151 - val_accuracy: 0.8179\n",
            "Epoch 9/50\n",
            "21/21 [==============================] - 0s 22ms/step - loss: 0.3385 - accuracy: 0.8455 - val_loss: 0.3947 - val_accuracy: 0.8179\n",
            "Epoch 10/50\n",
            "21/21 [==============================] - 0s 23ms/step - loss: 0.2806 - accuracy: 0.8598 - val_loss: 0.3619 - val_accuracy: 0.8478\n",
            "Epoch 11/50\n",
            "21/21 [==============================] - 0s 22ms/step - loss: 0.2388 - accuracy: 0.8755 - val_loss: 0.3226 - val_accuracy: 0.8597\n",
            "Epoch 12/50\n",
            "21/21 [==============================] - 0s 23ms/step - loss: 0.1788 - accuracy: 0.9222 - val_loss: 0.3468 - val_accuracy: 0.8716\n",
            "Epoch 13/50\n",
            "21/21 [==============================] - 0s 22ms/step - loss: 0.1233 - accuracy: 0.9541 - val_loss: 0.3752 - val_accuracy: 0.8776\n",
            "Epoch 14/50\n",
            "21/21 [==============================] - 1s 24ms/step - loss: 0.1510 - accuracy: 0.9321 - val_loss: 0.3462 - val_accuracy: 0.8806\n",
            "Epoch 15/50\n",
            "21/21 [==============================] - 0s 22ms/step - loss: 0.1055 - accuracy: 0.9552 - val_loss: 0.3631 - val_accuracy: 0.8836\n",
            "Epoch 16/50\n",
            "21/21 [==============================] - 0s 22ms/step - loss: 0.1271 - accuracy: 0.9465 - val_loss: 0.3533 - val_accuracy: 0.8746\n",
            "Epoch 17/50\n",
            "21/21 [==============================] - 0s 23ms/step - loss: 0.1065 - accuracy: 0.9563 - val_loss: 0.3577 - val_accuracy: 0.8746\n",
            "Epoch 18/50\n",
            "21/21 [==============================] - 1s 25ms/step - loss: 0.0988 - accuracy: 0.9556 - val_loss: 0.3644 - val_accuracy: 0.8806\n",
            "Epoch 19/50\n",
            "21/21 [==============================] - 0s 22ms/step - loss: 0.1021 - accuracy: 0.9573 - val_loss: 0.3591 - val_accuracy: 0.8746\n",
            "Epoch 20/50\n",
            "21/21 [==============================] - 0s 23ms/step - loss: 0.0960 - accuracy: 0.9623 - val_loss: 0.3627 - val_accuracy: 0.8776\n",
            "Epoch 21/50\n",
            "21/21 [==============================] - 0s 23ms/step - loss: 0.1022 - accuracy: 0.9537 - val_loss: 0.3703 - val_accuracy: 0.8836\n",
            "Epoch 22/50\n",
            "21/21 [==============================] - 0s 23ms/step - loss: 0.1052 - accuracy: 0.9536 - val_loss: 0.3602 - val_accuracy: 0.8776\n",
            "Epoch 23/50\n",
            "21/21 [==============================] - 0s 22ms/step - loss: 0.1024 - accuracy: 0.9509 - val_loss: 0.3653 - val_accuracy: 0.8806\n",
            "Epoch 24/50\n",
            "21/21 [==============================] - 0s 22ms/step - loss: 0.0947 - accuracy: 0.9581 - val_loss: 0.3695 - val_accuracy: 0.8776\n",
            "Epoch 25/50\n",
            "21/21 [==============================] - 1s 25ms/step - loss: 0.1125 - accuracy: 0.9434 - val_loss: 0.3713 - val_accuracy: 0.8806\n",
            "Epoch 26/50\n",
            "21/21 [==============================] - 0s 22ms/step - loss: 0.0917 - accuracy: 0.9627 - val_loss: 0.3742 - val_accuracy: 0.8806\n",
            "Epoch 27/50\n",
            "21/21 [==============================] - 0s 22ms/step - loss: 0.0943 - accuracy: 0.9558 - val_loss: 0.3825 - val_accuracy: 0.8806\n",
            "Epoch 28/50\n",
            "21/21 [==============================] - 0s 22ms/step - loss: 0.1014 - accuracy: 0.9501 - val_loss: 0.3814 - val_accuracy: 0.8716\n",
            "Epoch 29/50\n",
            "21/21 [==============================] - 0s 23ms/step - loss: 0.1032 - accuracy: 0.9505 - val_loss: 0.3849 - val_accuracy: 0.8806\n",
            "Epoch 30/50\n",
            "21/21 [==============================] - 0s 23ms/step - loss: 0.1047 - accuracy: 0.9507 - val_loss: 0.3830 - val_accuracy: 0.8806\n",
            "Epoch 31/50\n",
            "21/21 [==============================] - 0s 23ms/step - loss: 0.1055 - accuracy: 0.9466 - val_loss: 0.4097 - val_accuracy: 0.8836\n",
            "Epoch 32/50\n",
            "21/21 [==============================] - 0s 23ms/step - loss: 0.0999 - accuracy: 0.9548 - val_loss: 0.3807 - val_accuracy: 0.8776\n",
            "Epoch 33/50\n",
            "21/21 [==============================] - 0s 23ms/step - loss: 0.1036 - accuracy: 0.9498 - val_loss: 0.3884 - val_accuracy: 0.8836\n",
            "Epoch 34/50\n",
            "21/21 [==============================] - 0s 22ms/step - loss: 0.0894 - accuracy: 0.9608 - val_loss: 0.3765 - val_accuracy: 0.8806\n",
            "Epoch 35/50\n",
            "21/21 [==============================] - 0s 21ms/step - loss: 0.0879 - accuracy: 0.9582 - val_loss: 0.3789 - val_accuracy: 0.8806\n",
            "Epoch 36/50\n",
            "21/21 [==============================] - 0s 22ms/step - loss: 0.0985 - accuracy: 0.9561 - val_loss: 0.3817 - val_accuracy: 0.8776\n",
            "Epoch 37/50\n",
            "21/21 [==============================] - 0s 23ms/step - loss: 0.1012 - accuracy: 0.9516 - val_loss: 0.3831 - val_accuracy: 0.8806\n",
            "Epoch 38/50\n",
            "21/21 [==============================] - 0s 23ms/step - loss: 0.0988 - accuracy: 0.9517 - val_loss: 0.4069 - val_accuracy: 0.8836\n",
            "Epoch 39/50\n",
            "21/21 [==============================] - 0s 23ms/step - loss: 0.0978 - accuracy: 0.9579 - val_loss: 0.3781 - val_accuracy: 0.8776\n",
            "Epoch 40/50\n",
            "21/21 [==============================] - 0s 22ms/step - loss: 0.0995 - accuracy: 0.9502 - val_loss: 0.3853 - val_accuracy: 0.8896\n",
            "Epoch 41/50\n",
            "21/21 [==============================] - 0s 23ms/step - loss: 0.1090 - accuracy: 0.9413 - val_loss: 0.3905 - val_accuracy: 0.8776\n",
            "Epoch 42/50\n",
            "21/21 [==============================] - 1s 24ms/step - loss: 0.0918 - accuracy: 0.9573 - val_loss: 0.3902 - val_accuracy: 0.8806\n",
            "Epoch 43/50\n",
            "21/21 [==============================] - 0s 22ms/step - loss: 0.0918 - accuracy: 0.9561 - val_loss: 0.3927 - val_accuracy: 0.8806\n",
            "Epoch 44/50\n",
            "21/21 [==============================] - 0s 23ms/step - loss: 0.0972 - accuracy: 0.9517 - val_loss: 0.3908 - val_accuracy: 0.8806\n",
            "Epoch 45/50\n",
            "21/21 [==============================] - 0s 22ms/step - loss: 0.0853 - accuracy: 0.9598 - val_loss: 0.3923 - val_accuracy: 0.8746\n",
            "Epoch 46/50\n",
            "21/21 [==============================] - 0s 23ms/step - loss: 0.0880 - accuracy: 0.9572 - val_loss: 0.3966 - val_accuracy: 0.8806\n",
            "Epoch 47/50\n",
            "21/21 [==============================] - 0s 22ms/step - loss: 0.0942 - accuracy: 0.9567 - val_loss: 0.3990 - val_accuracy: 0.8806\n",
            "Epoch 48/50\n",
            "21/21 [==============================] - 0s 22ms/step - loss: 0.0977 - accuracy: 0.9513 - val_loss: 0.4126 - val_accuracy: 0.8836\n",
            "Epoch 49/50\n",
            "21/21 [==============================] - 0s 22ms/step - loss: 0.0995 - accuracy: 0.9484 - val_loss: 0.3966 - val_accuracy: 0.8776\n",
            "Epoch 50/50\n",
            "21/21 [==============================] - 0s 23ms/step - loss: 0.1057 - accuracy: 0.9469 - val_loss: 0.3817 - val_accuracy: 0.8776\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8208955223880597"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GJ0lll0f0s4R",
        "outputId": "8647e62d-8897-46f5-a92c-14b3c8698035"
      },
      "source": [
        "# Importing necessary modules.\n",
        "\n",
        "import pandas as pd \n",
        "import nltk\n",
        "import re\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# Shortlisting the columns to be used for building the skill set.\n",
        "\n",
        "columns = ['LanguageWorkedWith','LanguageDesireNextYear','DatabaseWorkedWith','DatabaseDesireNextYear',\n",
        "           'PlatformWorkedWith','PlatformDesireNextYear','FrameworkWorkedWith','FrameworkDesireNextYear',\n",
        "           'IDE','OperatingSystem','VersionControl']\n",
        "Skills = pd.read_csv(filepath_or_buffer='survey_results_public_skills.csv',usecols=columns)\n",
        "Skills = Skills.dropna()\n",
        "Skills['Combined_Skills'] = Skills[Skills.columns[1:]].apply(lambda x: ';'.join(x.dropna().astype(str)),axis=1)\n",
        "Skills['Skill_List'] = Skills['Combined_Skills'].str.split(\";\")\n",
        "Unique_Skills = set()\n",
        "print(Skills)\n",
        "\n",
        "# Adding all unique skills in a set.\n",
        "\n",
        "for i in Skills[\"Skill_List\"]:\n",
        "  for j in i:\n",
        "      Unique_Skills.add(j.lower())\n",
        "\n",
        "print(len(Unique_Skills))  \n",
        "print(Unique_Skills) \n",
        "\n",
        "# Filtering the rows with no skills.\n",
        "\n",
        "Jobs = pd.read_csv(filepath_or_buffer='jobs.csv')\n",
        "print(Jobs)\n",
        "\n",
        "JobDescriptions = pd.read_csv(filepath_or_buffer='jobs.csv')\n",
        "JobDescriptions = JobDescriptions.loc[JobDescriptions['skills'].str.contains('See',na=False,case=False)]\n",
        "JobDescriptions = JobDescriptions.loc[JobDescriptions['skills'].str.count(',')==0]\n",
        "JobDescriptions = JobDescriptions.reset_index(drop=True)\n",
        "print (JobDescriptions)\n",
        "\n",
        "\n",
        "# Predicting the skills with the help of jobdescription column by using the model trained above.\n",
        "\n",
        "for i in range(len(JobDescriptions)):\n",
        "  JobDescriptions.loc[i,\"skills\"] = \" \"\n",
        "\n",
        "  # Preprocessing the data\n",
        "  JobDescriptions.loc[i,\"jobdescription\"] = re.sub(r'\\[[0-9]*\\]',' ',str(JobDescriptions.loc[i,\"jobdescription\"]))\n",
        "  JobDescriptions.loc[i,\"jobdescription\"] = re.sub(r'\\s+',' ',JobDescriptions.loc[i,\"jobdescription\"])\n",
        "  JobDescriptions.loc[i,\"jobdescription\"] = JobDescriptions.loc[i,\"jobdescription\"].lower()\n",
        "  JobDescriptions.loc[i,\"jobdescription\"] = re.sub(r'\\d',' ',JobDescriptions.loc[i,\"jobdescription\"])\n",
        "  JobDescriptions.loc[i,\"jobdescription\"] = re.sub(r'\\s+',' ',JobDescriptions.loc[i,\"jobdescription\"])\n",
        "  \n",
        "  # Breaking down job description into sentences.\n",
        "  sentences = nltk.sent_tokenize(JobDescriptions.loc[i,\"jobdescription\"])\n",
        " \n",
        "  sentences = [nltk.word_tokenize(sentence) for sentence in sentences]\n",
        "\n",
        "  for j in range(len(sentences)):\n",
        "     sentences[j] = [word for word in sentences[j] if word not in stopwords.words('english')]\n",
        "    \n",
        "     for k in sentences[j]:\n",
        "       if k in Unique_Skills and k not in JobDescriptions.loc[i,\"skills\"] :\n",
        "         JobDescriptions.loc[i,\"skills\"] += k\n",
        "         JobDescriptions.loc[i,\"skills\"] += \",\" \n",
        "       elif k not in Unique_Skills:\n",
        "         onehot_repr=one_hot(k,voc_size) \n",
        "         embedded_docs=pad_sequences([onehot_repr],padding='pre',maxlen=words_length)\n",
        "         if model.predict_classes(embedded_docs)[0][0]==1:\n",
        "           JobDescriptions.loc[i,\"skills\"] += k\n",
        "           JobDescriptions.loc[i,\"skills\"] += \",\"  \n",
        "\n",
        "JobDescriptions[\"skills\"] = JobDescriptions[\"skills\"].str.rstrip(',')\n",
        "print(JobDescriptions)\n",
        "\n",
        "Jobs = pd.concat([Jobs, JobDescriptions]).reset_index(drop=True)\n",
        "Jobs = Jobs.drop_duplicates(subset=['uniq_id'], keep='last')\n",
        "Jobs = Jobs.reset_index(drop=True)\n",
        "print(Jobs)\n"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "                               LanguageWorkedWith  ...                                         Skill_List\n",
            "0                      JavaScript;Python;HTML;CSS  ...  [JavaScript, Python, HTML, CSS, Redis, SQL Ser...\n",
            "1                    JavaScript;Python;Bash/Shell  ...  [Go, Python, Redis, PostgreSQL, Memcached, Pos...\n",
            "5      Java;JavaScript;Python;TypeScript;HTML;CSS  ...  [C#, Go, Java, JavaScript, Python, SQL, TypeSc...\n",
            "13                                           Java  ...  [Java, Python, MongoDB, MySQL, Oracle, MariaDB...\n",
            "17                     C#;SQL;HTML;CSS;Bash/Shell  ...  [C#, F#, Haskell, SQL, Ocaml, SQL Server, Redi...\n",
            "...                                           ...  ...                                                ...\n",
            "92430                     PHP;Python;SQL;HTML;CSS  ...  [JavaScript, PHP, Python, SQL, Kotlin, HTML, C...\n",
            "92447                                         PHP  ...  [PHP, MySQL, MySQL, WordPress, WordPress, Node...\n",
            "92455                                     PHP;SQL  ...  [PHP, MySQL, MySQL, Oracle, WordPress, Android...\n",
            "92471                  Python;SQL;HTML;Bash/Shell  ...  [Python, SQL, TypeScript, CSS, Bash/Shell, SQL...\n",
            "92507                         TypeScript;HTML;CSS  ...  [TypeScript, HTML, CSS, PostgreSQL, PostgreSQL...\n",
            "\n",
            "[30607 rows x 13 columns]\n",
            "130\n",
            "{'rstudio', 'zip file back-ups', 'google cloud storage', 'ios', 'amazon rds/aurora', 'sharepoint', 'cordova', 'java', 'apple watch or apple tv', 'windows phone', 'swift', 'linux', 'c++', 'google cloud platform/app engine', 'firebase', 'git', 'android studio', 'microsoft azure (tables, cosmosdb, sql, etc)', 'android', 'rubymine', 'perl', 'zend', 'sql', '.net core', 'wordpress', 'drupal', 'esp8266', 'angular', 'python', 'linux-based', 'scala', 'netbeans', 'hack', 'matlab', 'r', 'ruby', 'mercurial', 'intellij', 'apache hbase', 'pycharm', 'f#', 'copying and pasting files to network shares', 'css', 'go', 'sublime text', 'amazon redshift', 'vim', 'spring', 'cobol', 'visual basic 6', 'django', 'apache hive', 'ibm db2', 'clojure', 'postgresql', 'atom', 'heroku', 'objective-c', 'notepad++', 'subversion', 'typescript', 'salesforce', 'elasticsearch', 'eclipse', 'spark', 'visual studio code', 'arduino', 'torch/pytorch', 'emacs', 'macos', 'sql server', 'kotlin', 'html', 'gaming console', 'mongodb', 'phpstorm', 'tensorflow', 'c#', 'ipython / jupyter', 'sqlite', 'cassandra', 'memcached', 'google home', 'amazon echo', 'mariadb', 'raspberry pi', 'bsd/unix', 'oracle', 'amazon dynamodb', 'vb.net', 'team foundation version control', 'light table', 'aws', 'rust', 'google bigquery', 'textmate', 'react', 'erlang', 'coda', 'bash/shell', 'hadoop', 'ocaml', 'mac os', 'node.js', 'coffeescript', 'vba', 'delphi/object pascal', 'mysql', 'lua', 'neo4j', 'javascript', 'ibm cloud or watson', 'xamarin', 'windows', 'komodo', 'xcode', 'assembly', \"i don't use version control\", 'mainframe', 'predix', 'visual studio', 'c', 'azure', 'groovy', 'php', 'julia', 'haskell', 'serverless', 'windows desktop or server', 'redis'}\n",
            "                                           advertiserurl  ...                           uniq_id\n",
            "0      https://www.dice.com/jobs/detail/AUTOMATION-TE...  ...  418ff92580b270ef4e7c14f0ddfc36b4\n",
            "1      https://www.dice.com/jobs/detail/Information-S...  ...  8aec88cba08d53da65ab99cf20f6f9d9\n",
            "2      https://www.dice.com/jobs/detail/Business-Solu...  ...  46baa1f69ac07779274bcd90b85d9a72\n",
            "3      https://www.dice.com/jobs/detail/Java-Develope...  ...  3941b2f206ae0f900c4fba4ac0b18719\n",
            "4      https://www.dice.com/jobs/detail/DevOps-Engine...  ...  45efa1f6bc65acc32bbbb953a1ed13b7\n",
            "...                                                  ...  ...                               ...\n",
            "21995  https://www.dice.com/jobs/detail/Web-Designer-...  ...  86e27ce6b7e631e55d69d142c7d43df2\n",
            "21996  https://www.dice.com/jobs/detail/Senior-Front-...  ...  4287c7ee3317ccf1edd76e238cf8e584\n",
            "21997  https://www.dice.com/jobs/detail/QA-Analyst-Sa...  ...  d7512f0181d69f83f96db38cd77a4d08\n",
            "21998  https://www.dice.com/jobs/detail/Tech-Lead%252...  ...  ec375268b494b3bcbed1635d64226112\n",
            "21999  https://www.dice.com/jobs/detail/C%2526%252347...  ...  9a4e8c27f74af4c0d2f6efbd420a8a91\n",
            "\n",
            "[22000 rows x 12 columns]\n",
            "                                         advertiserurl  ...                           uniq_id\n",
            "0    https://www.dice.com/jobs/detail/AUTOMATION-TE...  ...  418ff92580b270ef4e7c14f0ddfc36b4\n",
            "1    https://www.dice.com/jobs/detail/Java-Develope...  ...  3941b2f206ae0f900c4fba4ac0b18719\n",
            "2    https://www.dice.com/jobs/detail/Application-S...  ...  95c9127e2770172f454f3b83981eaa88\n",
            "3    https://www.dice.com/jobs/detail/Windows-Syste...  ...  9e5704d08bc07ddb6df9ef98b223b036\n",
            "4    https://www.dice.com/jobs/detail/Java-Architec...  ...  e4f57bc5366124a0a47cac27f557f9ec\n",
            "..                                                 ...  ...                               ...\n",
            "188  https://www.dice.com/jobs/detail/JR-Project-ma...  ...  72597cc210e6c518f05dc2cfdd6fd17f\n",
            "189  https://www.dice.com/jobs/detail/PC-Support-As...  ...  38e97bc0955ee08d7fff35bf9d2c7b6b\n",
            "190  https://www.dice.com/jobs/detail/Technical-Lea...  ...  ca3b2c097deffef3bef71e8e8dd7b567\n",
            "191  https://www.dice.com/jobs/detail/Applications-...  ...  4fa8a123b307765c21beef51693df0b5\n",
            "192  https://www.dice.com/jobs/detail/Tech-Project-...  ...  28adfb1f1cfef4419a0b85db460d7288\n",
            "\n",
            "[193 rows x 12 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                                         advertiserurl  ...                           uniq_id\n",
            "0    https://www.dice.com/jobs/detail/AUTOMATION-TE...  ...  418ff92580b270ef4e7c14f0ddfc36b4\n",
            "1    https://www.dice.com/jobs/detail/Java-Develope...  ...  3941b2f206ae0f900c4fba4ac0b18719\n",
            "2    https://www.dice.com/jobs/detail/Application-S...  ...  95c9127e2770172f454f3b83981eaa88\n",
            "3    https://www.dice.com/jobs/detail/Windows-Syste...  ...  9e5704d08bc07ddb6df9ef98b223b036\n",
            "4    https://www.dice.com/jobs/detail/Java-Architec...  ...  e4f57bc5366124a0a47cac27f557f9ec\n",
            "..                                                 ...  ...                               ...\n",
            "188  https://www.dice.com/jobs/detail/JR-Project-ma...  ...  72597cc210e6c518f05dc2cfdd6fd17f\n",
            "189  https://www.dice.com/jobs/detail/PC-Support-As...  ...  38e97bc0955ee08d7fff35bf9d2c7b6b\n",
            "190  https://www.dice.com/jobs/detail/Technical-Lea...  ...  ca3b2c097deffef3bef71e8e8dd7b567\n",
            "191  https://www.dice.com/jobs/detail/Applications-...  ...  4fa8a123b307765c21beef51693df0b5\n",
            "192  https://www.dice.com/jobs/detail/Tech-Project-...  ...  28adfb1f1cfef4419a0b85db460d7288\n",
            "\n",
            "[193 rows x 12 columns]\n",
            "                                           advertiserurl  ...                           uniq_id\n",
            "0      https://www.dice.com/jobs/detail/Information-S...  ...  8aec88cba08d53da65ab99cf20f6f9d9\n",
            "1      https://www.dice.com/jobs/detail/Business-Solu...  ...  46baa1f69ac07779274bcd90b85d9a72\n",
            "2      https://www.dice.com/jobs/detail/DevOps-Engine...  ...  45efa1f6bc65acc32bbbb953a1ed13b7\n",
            "3      https://www.dice.com/jobs/detail/SAP-FICO-Arch...  ...  e0ac9d926dda5e95162ef05adea7318c\n",
            "4      https://www.dice.com/jobs/detail/Network-Engin...  ...  e7e326053c586bd94e59f1fd74de4a1b\n",
            "...                                                  ...  ...                               ...\n",
            "21995  https://www.dice.com/jobs/detail/JR-Project-ma...  ...  72597cc210e6c518f05dc2cfdd6fd17f\n",
            "21996  https://www.dice.com/jobs/detail/PC-Support-As...  ...  38e97bc0955ee08d7fff35bf9d2c7b6b\n",
            "21997  https://www.dice.com/jobs/detail/Technical-Lea...  ...  ca3b2c097deffef3bef71e8e8dd7b567\n",
            "21998  https://www.dice.com/jobs/detail/Applications-...  ...  4fa8a123b307765c21beef51693df0b5\n",
            "21999  https://www.dice.com/jobs/detail/Tech-Project-...  ...  28adfb1f1cfef4419a0b85db460d7288\n",
            "\n",
            "[22000 rows x 12 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0QIKevjWuYQR"
      },
      "source": [
        "Jobs.to_csv('jobs_modified.csv')"
      ],
      "execution_count": 79,
      "outputs": []
    }
  ]
}